{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the necessary libraries\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 498/498 [00:07<00:00, 66.95it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15920, 384)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialising the Sentence Transformer model for encoding the sentences\n",
    "model = SentenceTransformer(\n",
    "    \"all-MiniLM-L6-v2\", device=\"cuda\"\n",
    ")  # or device=\"cpu\" if you don't have a GPU\n",
    "\n",
    "df = pd.read_json(\"G2_Cleaned.json\", lines=True)\n",
    "\n",
    "vectors = model.encode(\n",
    "    [row.name + \". \" + row.domain + \". \" + row.description for row in df.itertuples()],\n",
    "    show_progress_bar=True,\n",
    ")\n",
    "\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the vectors to a file\n",
    "np.save(\"product_vectors.npy\", vectors, allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import client library\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, Distance\n",
    "\n",
    "\n",
    "#Initialising the Qdrant client\n",
    "client = QdrantClient(\"http://localhost:6333\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a collection in Qdrant\n",
    "client.recreate_collection(\n",
    "    collection_name=\"G2products\",\n",
    "    vectors_config=VectorParams(size=384, distance=Distance.COSINE),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = open(\"G2_Cleaned.json\")\n",
    "\n",
    "# payload is now an iterator over startup data\n",
    "payload = map(json.loads, fd)\n",
    "\n",
    "# Load all vectors into memory, numpy array works as iterable for itself.\n",
    "# Other option would be to use Mmap, if you don't want to load all data into RAM\n",
    "vectors = np.load(\"product_vectors.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload vectors to Qdrant for Neural Search\n",
    "client.upload_collection(\n",
    "    collection_name=\"G2products\",\n",
    "    vectors=vectors,\n",
    "    payload=payload,\n",
    "    ids=None,  # Vector ids will be assigned automatically\n",
    "    batch_size=256,  # How many vectors will be uploaded in a single request?\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
